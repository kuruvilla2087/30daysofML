{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CIFAR 10 object detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuruvilla2087/30daysofML/blob/master/CIFAR_10_object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmhFRhn3w5rO"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVIx_KIigxPV"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation,GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.callbacks import LearningRateScheduler,ReduceLROnPlateau,EarlyStopping,ModelCheckpoint \n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import math"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3to3oK3ngc-"
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWo6ZN-nnnOb"
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train,y_train), (x_test,y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3cVKYpCnvvk"
      },
      "source": [
        "# convert to one hot encoing \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEIxS3atnztw",
        "outputId": "0123a2db-768e-4a95-c410-09e34ed438f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (50000, 10)\n",
            "(10000, 32, 32, 3) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm81G__PxJc0"
      },
      "source": [
        "# Normalising Data\n",
        "\n",
        "It is required to normalize the data so that all features come to a scale between 0 and 1. This helps better understanding by the network. It is also required to convert the data type of individual pixel value to float before normalization because float is more accurate than integers.\n",
        "\n",
        "**Caution:** If data type in not converted to float before dividing, then we may end up ceiling the data if proper typecast is not done.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io9V5hFjGJfp"
      },
      "source": [
        "# # normalize inputs from 0-255 to 0.0-1.0\n",
        "# x_train = x_train.astype('float32')\n",
        "# x_test = x_test.astype('float32')\n",
        "# x_train = x_train / 255.0\n",
        "# x_test = x_test / 255.0\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOKqQmYNxL5I"
      },
      "source": [
        "\n",
        "# Data Augmentation\n",
        "\n",
        "Data Augmentation is a great method to **indirectly acquire more data** from the already availabe data. This happens by horizontal or verticle flips, rotation of images, random cropping and many more image processing ways such as whitening, scaling and different channels improvization. \n",
        "Helps in generalization process\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QsudiUKxRa_"
      },
      "source": [
        "# Dense Block\n",
        "\n",
        "This is the actual feature extracter block.\n",
        "\n",
        "   1.  Architecture has **3 dense blocks**.\n",
        "    Batch Normalization helps in **equalising the outcome values** from convolution.\n",
        "    2. Activation function: **RELU**\n",
        "    3. **Dropout** is done after 3x3 convolution for **regularization purpose** where 20% of neurons are randomly shut down to avoid overfitting on train data.\n",
        "    4. **1x1 Convolution** is done to to reduce the number of channels before giving it to next layer so that it helps in achieving lower number of parameters and reducing model complexity.\n",
        "    5. Standard **3x3 Convolution** is followed.\n",
        "    6. The number of filters used in 1x1 is **four times(4x) the number of kernals** in 3x3 convolution as advised by the above mentioned paper. This helps by not losing too much of information when reduing the number of channels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34VDEiAd8DV5"
      },
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 16, dropout_rate = 0.25):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "      \n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        reluD_LAYER = Activation('relu')(BatchNorm)\n",
        "        Conv2D_1_1 = Conv2D(int(4*num_filter*compression), (1,1), use_bias=False ,kernel_initializer=\"he_uniform\",padding='same')(reluD_LAYER)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_1_1 = Dropout(dropout_rate)(Conv2D_1_1)\n",
        "                    \n",
        "        BatchNorm = BatchNormalization()(Conv2D_1_1)\n",
        "        reluD_LAYER = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,kernel_initializer=\"he_uniform\",padding='same')(reluD_LAYER)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "def transition(input, num_filter = 16, dropout_rate = 0.25):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(4*num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg    \n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    GblAvgPooling = GlobalAveragePooling2D()(relu)\n",
        "    #flat = Flatten()(GblAvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(GblAvgPooling)\n",
        "    \n",
        "    return output    "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5olrMedxZrt"
      },
      "source": [
        "# Model implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anPCpQWhhGb7"
      },
      "source": [
        "\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "l = 16\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "l = 16\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "l = 16\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "outputId": "c35b9839-012e-46c5-ef75-5dd4259af6ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_396 (Conv2D)             (None, 32, 32, 12)   324         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_396 (BatchN (None, 32, 32, 12)   48          conv2d_396[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 32, 32, 12)   0           batch_normalization_396[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_397 (Conv2D)             (None, 32, 32, 24)   288         activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_393 (Dropout)           (None, 32, 32, 24)   0           conv2d_397[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_397 (BatchN (None, 32, 32, 24)   96          dropout_393[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_397 (Activation)     (None, 32, 32, 24)   0           batch_normalization_397[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_398 (Conv2D)             (None, 32, 32, 6)    1296        activation_397[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_394 (Dropout)           (None, 32, 32, 6)    0           conv2d_398[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_192 (Concatenate)   (None, 32, 32, 18)   0           conv2d_396[0][0]                 \n",
            "                                                                 dropout_394[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_398 (BatchN (None, 32, 32, 18)   72          concatenate_192[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_398 (Activation)     (None, 32, 32, 18)   0           batch_normalization_398[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_399 (Conv2D)             (None, 32, 32, 24)   432         activation_398[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_395 (Dropout)           (None, 32, 32, 24)   0           conv2d_399[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_399 (BatchN (None, 32, 32, 24)   96          dropout_395[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_399 (Activation)     (None, 32, 32, 24)   0           batch_normalization_399[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, 32, 32, 6)    1296        activation_399[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_396 (Dropout)           (None, 32, 32, 6)    0           conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_193 (Concatenate)   (None, 32, 32, 24)   0           concatenate_192[0][0]            \n",
            "                                                                 dropout_396[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_400 (BatchN (None, 32, 32, 24)   96          concatenate_193[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_400 (Activation)     (None, 32, 32, 24)   0           batch_normalization_400[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, 32, 32, 24)   576         activation_400[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_397 (Dropout)           (None, 32, 32, 24)   0           conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_401 (BatchN (None, 32, 32, 24)   96          dropout_397[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_401 (Activation)     (None, 32, 32, 24)   0           batch_normalization_401[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, 32, 32, 6)    1296        activation_401[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_398 (Dropout)           (None, 32, 32, 6)    0           conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_194 (Concatenate)   (None, 32, 32, 30)   0           concatenate_193[0][0]            \n",
            "                                                                 dropout_398[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_402 (BatchN (None, 32, 32, 30)   120         concatenate_194[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_402 (Activation)     (None, 32, 32, 30)   0           batch_normalization_402[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, 32, 32, 24)   720         activation_402[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_399 (Dropout)           (None, 32, 32, 24)   0           conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_403 (BatchN (None, 32, 32, 24)   96          dropout_399[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_403 (Activation)     (None, 32, 32, 24)   0           batch_normalization_403[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, 32, 32, 6)    1296        activation_403[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_400 (Dropout)           (None, 32, 32, 6)    0           conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_195 (Concatenate)   (None, 32, 32, 36)   0           concatenate_194[0][0]            \n",
            "                                                                 dropout_400[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_404 (BatchN (None, 32, 32, 36)   144         concatenate_195[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_404 (Activation)     (None, 32, 32, 36)   0           batch_normalization_404[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_405 (Conv2D)             (None, 32, 32, 24)   864         activation_404[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_401 (Dropout)           (None, 32, 32, 24)   0           conv2d_405[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_405 (BatchN (None, 32, 32, 24)   96          dropout_401[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_405 (Activation)     (None, 32, 32, 24)   0           batch_normalization_405[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_406 (Conv2D)             (None, 32, 32, 6)    1296        activation_405[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_402 (Dropout)           (None, 32, 32, 6)    0           conv2d_406[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_196 (Concatenate)   (None, 32, 32, 42)   0           concatenate_195[0][0]            \n",
            "                                                                 dropout_402[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_406 (BatchN (None, 32, 32, 42)   168         concatenate_196[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_406 (Activation)     (None, 32, 32, 42)   0           batch_normalization_406[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_407 (Conv2D)             (None, 32, 32, 24)   1008        activation_406[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_403 (Dropout)           (None, 32, 32, 24)   0           conv2d_407[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_407 (BatchN (None, 32, 32, 24)   96          dropout_403[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_407 (Activation)     (None, 32, 32, 24)   0           batch_normalization_407[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_408 (Conv2D)             (None, 32, 32, 6)    1296        activation_407[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_404 (Dropout)           (None, 32, 32, 6)    0           conv2d_408[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_197 (Concatenate)   (None, 32, 32, 48)   0           concatenate_196[0][0]            \n",
            "                                                                 dropout_404[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_408 (BatchN (None, 32, 32, 48)   192         concatenate_197[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_408 (Activation)     (None, 32, 32, 48)   0           batch_normalization_408[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_409 (Conv2D)             (None, 32, 32, 24)   1152        activation_408[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_405 (Dropout)           (None, 32, 32, 24)   0           conv2d_409[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_409 (BatchN (None, 32, 32, 24)   96          dropout_405[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_409 (Activation)     (None, 32, 32, 24)   0           batch_normalization_409[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_410 (Conv2D)             (None, 32, 32, 6)    1296        activation_409[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_406 (Dropout)           (None, 32, 32, 6)    0           conv2d_410[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_198 (Concatenate)   (None, 32, 32, 54)   0           concatenate_197[0][0]            \n",
            "                                                                 dropout_406[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_410 (BatchN (None, 32, 32, 54)   216         concatenate_198[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_410 (Activation)     (None, 32, 32, 54)   0           batch_normalization_410[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_411 (Conv2D)             (None, 32, 32, 24)   1296        activation_410[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_407 (Dropout)           (None, 32, 32, 24)   0           conv2d_411[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_411 (BatchN (None, 32, 32, 24)   96          dropout_407[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_411 (Activation)     (None, 32, 32, 24)   0           batch_normalization_411[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_412 (Conv2D)             (None, 32, 32, 6)    1296        activation_411[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_408 (Dropout)           (None, 32, 32, 6)    0           conv2d_412[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_199 (Concatenate)   (None, 32, 32, 60)   0           concatenate_198[0][0]            \n",
            "                                                                 dropout_408[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_412 (BatchN (None, 32, 32, 60)   240         concatenate_199[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_412 (Activation)     (None, 32, 32, 60)   0           batch_normalization_412[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_413 (Conv2D)             (None, 32, 32, 24)   1440        activation_412[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_409 (Dropout)           (None, 32, 32, 24)   0           conv2d_413[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_413 (BatchN (None, 32, 32, 24)   96          dropout_409[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_413 (Activation)     (None, 32, 32, 24)   0           batch_normalization_413[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_414 (Conv2D)             (None, 32, 32, 6)    1296        activation_413[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_410 (Dropout)           (None, 32, 32, 6)    0           conv2d_414[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_200 (Concatenate)   (None, 32, 32, 66)   0           concatenate_199[0][0]            \n",
            "                                                                 dropout_410[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_414 (BatchN (None, 32, 32, 66)   264         concatenate_200[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_414 (Activation)     (None, 32, 32, 66)   0           batch_normalization_414[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_415 (Conv2D)             (None, 32, 32, 24)   1584        activation_414[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_411 (Dropout)           (None, 32, 32, 24)   0           conv2d_415[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_415 (BatchN (None, 32, 32, 24)   96          dropout_411[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_415 (Activation)     (None, 32, 32, 24)   0           batch_normalization_415[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_416 (Conv2D)             (None, 32, 32, 6)    1296        activation_415[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_412 (Dropout)           (None, 32, 32, 6)    0           conv2d_416[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_201 (Concatenate)   (None, 32, 32, 72)   0           concatenate_200[0][0]            \n",
            "                                                                 dropout_412[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_416 (BatchN (None, 32, 32, 72)   288         concatenate_201[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_416 (Activation)     (None, 32, 32, 72)   0           batch_normalization_416[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_417 (Conv2D)             (None, 32, 32, 24)   1728        activation_416[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_413 (Dropout)           (None, 32, 32, 24)   0           conv2d_417[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_417 (BatchN (None, 32, 32, 24)   96          dropout_413[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_417 (Activation)     (None, 32, 32, 24)   0           batch_normalization_417[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_418 (Conv2D)             (None, 32, 32, 6)    1296        activation_417[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_414 (Dropout)           (None, 32, 32, 6)    0           conv2d_418[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_202 (Concatenate)   (None, 32, 32, 78)   0           concatenate_201[0][0]            \n",
            "                                                                 dropout_414[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_418 (BatchN (None, 32, 32, 78)   312         concatenate_202[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_418 (Activation)     (None, 32, 32, 78)   0           batch_normalization_418[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_419 (Conv2D)             (None, 32, 32, 24)   1872        activation_418[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_415 (Dropout)           (None, 32, 32, 24)   0           conv2d_419[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_419 (BatchN (None, 32, 32, 24)   96          dropout_415[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_419 (Activation)     (None, 32, 32, 24)   0           batch_normalization_419[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_420 (Conv2D)             (None, 32, 32, 6)    1296        activation_419[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_416 (Dropout)           (None, 32, 32, 6)    0           conv2d_420[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_203 (Concatenate)   (None, 32, 32, 84)   0           concatenate_202[0][0]            \n",
            "                                                                 dropout_416[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_420 (BatchN (None, 32, 32, 84)   336         concatenate_203[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_420 (Activation)     (None, 32, 32, 84)   0           batch_normalization_420[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_421 (Conv2D)             (None, 32, 32, 24)   2016        activation_420[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_417 (Dropout)           (None, 32, 32, 24)   0           conv2d_421[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_421 (BatchN (None, 32, 32, 24)   96          dropout_417[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_421 (Activation)     (None, 32, 32, 24)   0           batch_normalization_421[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_422 (Conv2D)             (None, 32, 32, 6)    1296        activation_421[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_418 (Dropout)           (None, 32, 32, 6)    0           conv2d_422[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_204 (Concatenate)   (None, 32, 32, 90)   0           concatenate_203[0][0]            \n",
            "                                                                 dropout_418[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_422 (BatchN (None, 32, 32, 90)   360         concatenate_204[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_422 (Activation)     (None, 32, 32, 90)   0           batch_normalization_422[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_423 (Conv2D)             (None, 32, 32, 24)   2160        activation_422[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_419 (Dropout)           (None, 32, 32, 24)   0           conv2d_423[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_423 (BatchN (None, 32, 32, 24)   96          dropout_419[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_423 (Activation)     (None, 32, 32, 24)   0           batch_normalization_423[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_424 (Conv2D)             (None, 32, 32, 6)    1296        activation_423[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_420 (Dropout)           (None, 32, 32, 6)    0           conv2d_424[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_205 (Concatenate)   (None, 32, 32, 96)   0           concatenate_204[0][0]            \n",
            "                                                                 dropout_420[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_424 (BatchN (None, 32, 32, 96)   384         concatenate_205[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_424 (Activation)     (None, 32, 32, 96)   0           batch_normalization_424[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_425 (Conv2D)             (None, 32, 32, 24)   2304        activation_424[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_421 (Dropout)           (None, 32, 32, 24)   0           conv2d_425[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_425 (BatchN (None, 32, 32, 24)   96          dropout_421[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_425 (Activation)     (None, 32, 32, 24)   0           batch_normalization_425[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_426 (Conv2D)             (None, 32, 32, 6)    1296        activation_425[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_422 (Dropout)           (None, 32, 32, 6)    0           conv2d_426[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_206 (Concatenate)   (None, 32, 32, 102)  0           concatenate_205[0][0]            \n",
            "                                                                 dropout_422[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_426 (BatchN (None, 32, 32, 102)  408         concatenate_206[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_426 (Activation)     (None, 32, 32, 102)  0           batch_normalization_426[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_427 (Conv2D)             (None, 32, 32, 24)   2448        activation_426[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_423 (Dropout)           (None, 32, 32, 24)   0           conv2d_427[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_427 (BatchN (None, 32, 32, 24)   96          dropout_423[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_427 (Activation)     (None, 32, 32, 24)   0           batch_normalization_427[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_428 (Conv2D)             (None, 32, 32, 6)    1296        activation_427[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_424 (Dropout)           (None, 32, 32, 6)    0           conv2d_428[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_207 (Concatenate)   (None, 32, 32, 108)  0           concatenate_206[0][0]            \n",
            "                                                                 dropout_424[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_428 (BatchN (None, 32, 32, 108)  432         concatenate_207[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_428 (Activation)     (None, 32, 32, 108)  0           batch_normalization_428[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_429 (Conv2D)             (None, 32, 32, 24)   2592        activation_428[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_425 (Dropout)           (None, 32, 32, 24)   0           conv2d_429[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 24)   0           dropout_425[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_429 (BatchN (None, 16, 16, 24)   96          average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_429 (Activation)     (None, 16, 16, 24)   0           batch_normalization_429[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_430 (Conv2D)             (None, 16, 16, 24)   576         activation_429[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_426 (Dropout)           (None, 16, 16, 24)   0           conv2d_430[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_430 (BatchN (None, 16, 16, 24)   96          dropout_426[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_430 (Activation)     (None, 16, 16, 24)   0           batch_normalization_430[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_431 (Conv2D)             (None, 16, 16, 6)    1296        activation_430[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_427 (Dropout)           (None, 16, 16, 6)    0           conv2d_431[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_208 (Concatenate)   (None, 16, 16, 30)   0           average_pooling2d_9[0][0]        \n",
            "                                                                 dropout_427[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_431 (BatchN (None, 16, 16, 30)   120         concatenate_208[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_431 (Activation)     (None, 16, 16, 30)   0           batch_normalization_431[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_432 (Conv2D)             (None, 16, 16, 24)   720         activation_431[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_428 (Dropout)           (None, 16, 16, 24)   0           conv2d_432[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_432 (BatchN (None, 16, 16, 24)   96          dropout_428[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_432 (Activation)     (None, 16, 16, 24)   0           batch_normalization_432[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_433 (Conv2D)             (None, 16, 16, 6)    1296        activation_432[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_429 (Dropout)           (None, 16, 16, 6)    0           conv2d_433[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_209 (Concatenate)   (None, 16, 16, 36)   0           concatenate_208[0][0]            \n",
            "                                                                 dropout_429[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_433 (BatchN (None, 16, 16, 36)   144         concatenate_209[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_433 (Activation)     (None, 16, 16, 36)   0           batch_normalization_433[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_434 (Conv2D)             (None, 16, 16, 24)   864         activation_433[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_430 (Dropout)           (None, 16, 16, 24)   0           conv2d_434[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_434 (BatchN (None, 16, 16, 24)   96          dropout_430[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_434 (Activation)     (None, 16, 16, 24)   0           batch_normalization_434[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_435 (Conv2D)             (None, 16, 16, 6)    1296        activation_434[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_431 (Dropout)           (None, 16, 16, 6)    0           conv2d_435[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_210 (Concatenate)   (None, 16, 16, 42)   0           concatenate_209[0][0]            \n",
            "                                                                 dropout_431[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_435 (BatchN (None, 16, 16, 42)   168         concatenate_210[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_435 (Activation)     (None, 16, 16, 42)   0           batch_normalization_435[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_436 (Conv2D)             (None, 16, 16, 24)   1008        activation_435[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_432 (Dropout)           (None, 16, 16, 24)   0           conv2d_436[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_436 (BatchN (None, 16, 16, 24)   96          dropout_432[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_436 (Activation)     (None, 16, 16, 24)   0           batch_normalization_436[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_437 (Conv2D)             (None, 16, 16, 6)    1296        activation_436[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_433 (Dropout)           (None, 16, 16, 6)    0           conv2d_437[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_211 (Concatenate)   (None, 16, 16, 48)   0           concatenate_210[0][0]            \n",
            "                                                                 dropout_433[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_437 (BatchN (None, 16, 16, 48)   192         concatenate_211[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_437 (Activation)     (None, 16, 16, 48)   0           batch_normalization_437[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_438 (Conv2D)             (None, 16, 16, 24)   1152        activation_437[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_434 (Dropout)           (None, 16, 16, 24)   0           conv2d_438[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_438 (BatchN (None, 16, 16, 24)   96          dropout_434[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_438 (Activation)     (None, 16, 16, 24)   0           batch_normalization_438[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_439 (Conv2D)             (None, 16, 16, 6)    1296        activation_438[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_435 (Dropout)           (None, 16, 16, 6)    0           conv2d_439[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_212 (Concatenate)   (None, 16, 16, 54)   0           concatenate_211[0][0]            \n",
            "                                                                 dropout_435[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_439 (BatchN (None, 16, 16, 54)   216         concatenate_212[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_439 (Activation)     (None, 16, 16, 54)   0           batch_normalization_439[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_440 (Conv2D)             (None, 16, 16, 24)   1296        activation_439[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_436 (Dropout)           (None, 16, 16, 24)   0           conv2d_440[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_440 (BatchN (None, 16, 16, 24)   96          dropout_436[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_440 (Activation)     (None, 16, 16, 24)   0           batch_normalization_440[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_441 (Conv2D)             (None, 16, 16, 6)    1296        activation_440[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_437 (Dropout)           (None, 16, 16, 6)    0           conv2d_441[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_213 (Concatenate)   (None, 16, 16, 60)   0           concatenate_212[0][0]            \n",
            "                                                                 dropout_437[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_441 (BatchN (None, 16, 16, 60)   240         concatenate_213[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_441 (Activation)     (None, 16, 16, 60)   0           batch_normalization_441[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_442 (Conv2D)             (None, 16, 16, 24)   1440        activation_441[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_438 (Dropout)           (None, 16, 16, 24)   0           conv2d_442[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_442 (BatchN (None, 16, 16, 24)   96          dropout_438[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_442 (Activation)     (None, 16, 16, 24)   0           batch_normalization_442[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_443 (Conv2D)             (None, 16, 16, 6)    1296        activation_442[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_439 (Dropout)           (None, 16, 16, 6)    0           conv2d_443[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_214 (Concatenate)   (None, 16, 16, 66)   0           concatenate_213[0][0]            \n",
            "                                                                 dropout_439[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_443 (BatchN (None, 16, 16, 66)   264         concatenate_214[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_443 (Activation)     (None, 16, 16, 66)   0           batch_normalization_443[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_444 (Conv2D)             (None, 16, 16, 24)   1584        activation_443[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_440 (Dropout)           (None, 16, 16, 24)   0           conv2d_444[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_444 (BatchN (None, 16, 16, 24)   96          dropout_440[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_444 (Activation)     (None, 16, 16, 24)   0           batch_normalization_444[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_445 (Conv2D)             (None, 16, 16, 6)    1296        activation_444[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_441 (Dropout)           (None, 16, 16, 6)    0           conv2d_445[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_215 (Concatenate)   (None, 16, 16, 72)   0           concatenate_214[0][0]            \n",
            "                                                                 dropout_441[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_445 (BatchN (None, 16, 16, 72)   288         concatenate_215[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_445 (Activation)     (None, 16, 16, 72)   0           batch_normalization_445[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_446 (Conv2D)             (None, 16, 16, 24)   1728        activation_445[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_442 (Dropout)           (None, 16, 16, 24)   0           conv2d_446[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_446 (BatchN (None, 16, 16, 24)   96          dropout_442[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_446 (Activation)     (None, 16, 16, 24)   0           batch_normalization_446[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_447 (Conv2D)             (None, 16, 16, 6)    1296        activation_446[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_443 (Dropout)           (None, 16, 16, 6)    0           conv2d_447[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_216 (Concatenate)   (None, 16, 16, 78)   0           concatenate_215[0][0]            \n",
            "                                                                 dropout_443[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_447 (BatchN (None, 16, 16, 78)   312         concatenate_216[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_447 (Activation)     (None, 16, 16, 78)   0           batch_normalization_447[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_448 (Conv2D)             (None, 16, 16, 24)   1872        activation_447[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_444 (Dropout)           (None, 16, 16, 24)   0           conv2d_448[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_448 (BatchN (None, 16, 16, 24)   96          dropout_444[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_448 (Activation)     (None, 16, 16, 24)   0           batch_normalization_448[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_449 (Conv2D)             (None, 16, 16, 6)    1296        activation_448[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_445 (Dropout)           (None, 16, 16, 6)    0           conv2d_449[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_217 (Concatenate)   (None, 16, 16, 84)   0           concatenate_216[0][0]            \n",
            "                                                                 dropout_445[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_449 (BatchN (None, 16, 16, 84)   336         concatenate_217[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_449 (Activation)     (None, 16, 16, 84)   0           batch_normalization_449[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_450 (Conv2D)             (None, 16, 16, 24)   2016        activation_449[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_446 (Dropout)           (None, 16, 16, 24)   0           conv2d_450[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_450 (BatchN (None, 16, 16, 24)   96          dropout_446[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_450 (Activation)     (None, 16, 16, 24)   0           batch_normalization_450[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_451 (Conv2D)             (None, 16, 16, 6)    1296        activation_450[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_447 (Dropout)           (None, 16, 16, 6)    0           conv2d_451[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_218 (Concatenate)   (None, 16, 16, 90)   0           concatenate_217[0][0]            \n",
            "                                                                 dropout_447[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_451 (BatchN (None, 16, 16, 90)   360         concatenate_218[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_451 (Activation)     (None, 16, 16, 90)   0           batch_normalization_451[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_452 (Conv2D)             (None, 16, 16, 24)   2160        activation_451[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_448 (Dropout)           (None, 16, 16, 24)   0           conv2d_452[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_452 (BatchN (None, 16, 16, 24)   96          dropout_448[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_452 (Activation)     (None, 16, 16, 24)   0           batch_normalization_452[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_453 (Conv2D)             (None, 16, 16, 6)    1296        activation_452[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_449 (Dropout)           (None, 16, 16, 6)    0           conv2d_453[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_219 (Concatenate)   (None, 16, 16, 96)   0           concatenate_218[0][0]            \n",
            "                                                                 dropout_449[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_453 (BatchN (None, 16, 16, 96)   384         concatenate_219[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_453 (Activation)     (None, 16, 16, 96)   0           batch_normalization_453[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_454 (Conv2D)             (None, 16, 16, 24)   2304        activation_453[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_450 (Dropout)           (None, 16, 16, 24)   0           conv2d_454[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_454 (BatchN (None, 16, 16, 24)   96          dropout_450[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_454 (Activation)     (None, 16, 16, 24)   0           batch_normalization_454[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_455 (Conv2D)             (None, 16, 16, 6)    1296        activation_454[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_451 (Dropout)           (None, 16, 16, 6)    0           conv2d_455[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_220 (Concatenate)   (None, 16, 16, 102)  0           concatenate_219[0][0]            \n",
            "                                                                 dropout_451[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_455 (BatchN (None, 16, 16, 102)  408         concatenate_220[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_455 (Activation)     (None, 16, 16, 102)  0           batch_normalization_455[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_456 (Conv2D)             (None, 16, 16, 24)   2448        activation_455[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_452 (Dropout)           (None, 16, 16, 24)   0           conv2d_456[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_456 (BatchN (None, 16, 16, 24)   96          dropout_452[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_456 (Activation)     (None, 16, 16, 24)   0           batch_normalization_456[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_457 (Conv2D)             (None, 16, 16, 6)    1296        activation_456[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_453 (Dropout)           (None, 16, 16, 6)    0           conv2d_457[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_221 (Concatenate)   (None, 16, 16, 108)  0           concatenate_220[0][0]            \n",
            "                                                                 dropout_453[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_457 (BatchN (None, 16, 16, 108)  432         concatenate_221[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_457 (Activation)     (None, 16, 16, 108)  0           batch_normalization_457[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_458 (Conv2D)             (None, 16, 16, 24)   2592        activation_457[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_454 (Dropout)           (None, 16, 16, 24)   0           conv2d_458[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_458 (BatchN (None, 16, 16, 24)   96          dropout_454[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_458 (Activation)     (None, 16, 16, 24)   0           batch_normalization_458[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_459 (Conv2D)             (None, 16, 16, 6)    1296        activation_458[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_455 (Dropout)           (None, 16, 16, 6)    0           conv2d_459[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_222 (Concatenate)   (None, 16, 16, 114)  0           concatenate_221[0][0]            \n",
            "                                                                 dropout_455[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_459 (BatchN (None, 16, 16, 114)  456         concatenate_222[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_459 (Activation)     (None, 16, 16, 114)  0           batch_normalization_459[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_460 (Conv2D)             (None, 16, 16, 24)   2736        activation_459[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_456 (Dropout)           (None, 16, 16, 24)   0           conv2d_460[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_460 (BatchN (None, 16, 16, 24)   96          dropout_456[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_460 (Activation)     (None, 16, 16, 24)   0           batch_normalization_460[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_461 (Conv2D)             (None, 16, 16, 6)    1296        activation_460[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_457 (Dropout)           (None, 16, 16, 6)    0           conv2d_461[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_223 (Concatenate)   (None, 16, 16, 120)  0           concatenate_222[0][0]            \n",
            "                                                                 dropout_457[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_461 (BatchN (None, 16, 16, 120)  480         concatenate_223[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_461 (Activation)     (None, 16, 16, 120)  0           batch_normalization_461[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_462 (Conv2D)             (None, 16, 16, 24)   2880        activation_461[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_458 (Dropout)           (None, 16, 16, 24)   0           conv2d_462[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 8, 8, 24)     0           dropout_458[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_462 (BatchN (None, 8, 8, 24)     96          average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_462 (Activation)     (None, 8, 8, 24)     0           batch_normalization_462[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_463 (Conv2D)             (None, 8, 8, 24)     576         activation_462[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_459 (Dropout)           (None, 8, 8, 24)     0           conv2d_463[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_463 (BatchN (None, 8, 8, 24)     96          dropout_459[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_463 (Activation)     (None, 8, 8, 24)     0           batch_normalization_463[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_464 (Conv2D)             (None, 8, 8, 6)      1296        activation_463[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_460 (Dropout)           (None, 8, 8, 6)      0           conv2d_464[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_224 (Concatenate)   (None, 8, 8, 30)     0           average_pooling2d_10[0][0]       \n",
            "                                                                 dropout_460[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_464 (BatchN (None, 8, 8, 30)     120         concatenate_224[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_464 (Activation)     (None, 8, 8, 30)     0           batch_normalization_464[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_465 (Conv2D)             (None, 8, 8, 24)     720         activation_464[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_461 (Dropout)           (None, 8, 8, 24)     0           conv2d_465[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_465 (BatchN (None, 8, 8, 24)     96          dropout_461[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_465 (Activation)     (None, 8, 8, 24)     0           batch_normalization_465[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_466 (Conv2D)             (None, 8, 8, 6)      1296        activation_465[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_462 (Dropout)           (None, 8, 8, 6)      0           conv2d_466[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_225 (Concatenate)   (None, 8, 8, 36)     0           concatenate_224[0][0]            \n",
            "                                                                 dropout_462[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_466 (BatchN (None, 8, 8, 36)     144         concatenate_225[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_466 (Activation)     (None, 8, 8, 36)     0           batch_normalization_466[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_467 (Conv2D)             (None, 8, 8, 24)     864         activation_466[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_463 (Dropout)           (None, 8, 8, 24)     0           conv2d_467[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_467 (BatchN (None, 8, 8, 24)     96          dropout_463[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_467 (Activation)     (None, 8, 8, 24)     0           batch_normalization_467[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_468 (Conv2D)             (None, 8, 8, 6)      1296        activation_467[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_464 (Dropout)           (None, 8, 8, 6)      0           conv2d_468[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_226 (Concatenate)   (None, 8, 8, 42)     0           concatenate_225[0][0]            \n",
            "                                                                 dropout_464[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_468 (BatchN (None, 8, 8, 42)     168         concatenate_226[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_468 (Activation)     (None, 8, 8, 42)     0           batch_normalization_468[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_469 (Conv2D)             (None, 8, 8, 24)     1008        activation_468[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_465 (Dropout)           (None, 8, 8, 24)     0           conv2d_469[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_469 (BatchN (None, 8, 8, 24)     96          dropout_465[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_469 (Activation)     (None, 8, 8, 24)     0           batch_normalization_469[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_470 (Conv2D)             (None, 8, 8, 6)      1296        activation_469[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_466 (Dropout)           (None, 8, 8, 6)      0           conv2d_470[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_227 (Concatenate)   (None, 8, 8, 48)     0           concatenate_226[0][0]            \n",
            "                                                                 dropout_466[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_470 (BatchN (None, 8, 8, 48)     192         concatenate_227[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_470 (Activation)     (None, 8, 8, 48)     0           batch_normalization_470[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_471 (Conv2D)             (None, 8, 8, 24)     1152        activation_470[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_467 (Dropout)           (None, 8, 8, 24)     0           conv2d_471[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_471 (BatchN (None, 8, 8, 24)     96          dropout_467[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_471 (Activation)     (None, 8, 8, 24)     0           batch_normalization_471[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_472 (Conv2D)             (None, 8, 8, 6)      1296        activation_471[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_468 (Dropout)           (None, 8, 8, 6)      0           conv2d_472[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_228 (Concatenate)   (None, 8, 8, 54)     0           concatenate_227[0][0]            \n",
            "                                                                 dropout_468[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_472 (BatchN (None, 8, 8, 54)     216         concatenate_228[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_472 (Activation)     (None, 8, 8, 54)     0           batch_normalization_472[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_473 (Conv2D)             (None, 8, 8, 24)     1296        activation_472[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_469 (Dropout)           (None, 8, 8, 24)     0           conv2d_473[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_473 (BatchN (None, 8, 8, 24)     96          dropout_469[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_473 (Activation)     (None, 8, 8, 24)     0           batch_normalization_473[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_474 (Conv2D)             (None, 8, 8, 6)      1296        activation_473[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_470 (Dropout)           (None, 8, 8, 6)      0           conv2d_474[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_229 (Concatenate)   (None, 8, 8, 60)     0           concatenate_228[0][0]            \n",
            "                                                                 dropout_470[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_474 (BatchN (None, 8, 8, 60)     240         concatenate_229[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_474 (Activation)     (None, 8, 8, 60)     0           batch_normalization_474[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_475 (Conv2D)             (None, 8, 8, 24)     1440        activation_474[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_471 (Dropout)           (None, 8, 8, 24)     0           conv2d_475[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_475 (BatchN (None, 8, 8, 24)     96          dropout_471[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_475 (Activation)     (None, 8, 8, 24)     0           batch_normalization_475[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_476 (Conv2D)             (None, 8, 8, 6)      1296        activation_475[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_472 (Dropout)           (None, 8, 8, 6)      0           conv2d_476[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_230 (Concatenate)   (None, 8, 8, 66)     0           concatenate_229[0][0]            \n",
            "                                                                 dropout_472[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_476 (BatchN (None, 8, 8, 66)     264         concatenate_230[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_476 (Activation)     (None, 8, 8, 66)     0           batch_normalization_476[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_477 (Conv2D)             (None, 8, 8, 24)     1584        activation_476[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_473 (Dropout)           (None, 8, 8, 24)     0           conv2d_477[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_477 (BatchN (None, 8, 8, 24)     96          dropout_473[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_477 (Activation)     (None, 8, 8, 24)     0           batch_normalization_477[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_478 (Conv2D)             (None, 8, 8, 6)      1296        activation_477[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_474 (Dropout)           (None, 8, 8, 6)      0           conv2d_478[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_231 (Concatenate)   (None, 8, 8, 72)     0           concatenate_230[0][0]            \n",
            "                                                                 dropout_474[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_478 (BatchN (None, 8, 8, 72)     288         concatenate_231[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_478 (Activation)     (None, 8, 8, 72)     0           batch_normalization_478[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_479 (Conv2D)             (None, 8, 8, 24)     1728        activation_478[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_475 (Dropout)           (None, 8, 8, 24)     0           conv2d_479[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_479 (BatchN (None, 8, 8, 24)     96          dropout_475[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_479 (Activation)     (None, 8, 8, 24)     0           batch_normalization_479[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_480 (Conv2D)             (None, 8, 8, 6)      1296        activation_479[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_476 (Dropout)           (None, 8, 8, 6)      0           conv2d_480[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_232 (Concatenate)   (None, 8, 8, 78)     0           concatenate_231[0][0]            \n",
            "                                                                 dropout_476[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_480 (BatchN (None, 8, 8, 78)     312         concatenate_232[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_480 (Activation)     (None, 8, 8, 78)     0           batch_normalization_480[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_481 (Conv2D)             (None, 8, 8, 24)     1872        activation_480[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_477 (Dropout)           (None, 8, 8, 24)     0           conv2d_481[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_481 (BatchN (None, 8, 8, 24)     96          dropout_477[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_481 (Activation)     (None, 8, 8, 24)     0           batch_normalization_481[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_482 (Conv2D)             (None, 8, 8, 6)      1296        activation_481[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_478 (Dropout)           (None, 8, 8, 6)      0           conv2d_482[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_233 (Concatenate)   (None, 8, 8, 84)     0           concatenate_232[0][0]            \n",
            "                                                                 dropout_478[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_482 (BatchN (None, 8, 8, 84)     336         concatenate_233[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_482 (Activation)     (None, 8, 8, 84)     0           batch_normalization_482[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_483 (Conv2D)             (None, 8, 8, 24)     2016        activation_482[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_479 (Dropout)           (None, 8, 8, 24)     0           conv2d_483[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_483 (BatchN (None, 8, 8, 24)     96          dropout_479[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_483 (Activation)     (None, 8, 8, 24)     0           batch_normalization_483[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_484 (Conv2D)             (None, 8, 8, 6)      1296        activation_483[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_480 (Dropout)           (None, 8, 8, 6)      0           conv2d_484[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_234 (Concatenate)   (None, 8, 8, 90)     0           concatenate_233[0][0]            \n",
            "                                                                 dropout_480[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_484 (BatchN (None, 8, 8, 90)     360         concatenate_234[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_484 (Activation)     (None, 8, 8, 90)     0           batch_normalization_484[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_485 (Conv2D)             (None, 8, 8, 24)     2160        activation_484[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_481 (Dropout)           (None, 8, 8, 24)     0           conv2d_485[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_485 (BatchN (None, 8, 8, 24)     96          dropout_481[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_485 (Activation)     (None, 8, 8, 24)     0           batch_normalization_485[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_486 (Conv2D)             (None, 8, 8, 6)      1296        activation_485[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_482 (Dropout)           (None, 8, 8, 6)      0           conv2d_486[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_235 (Concatenate)   (None, 8, 8, 96)     0           concatenate_234[0][0]            \n",
            "                                                                 dropout_482[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_486 (BatchN (None, 8, 8, 96)     384         concatenate_235[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_486 (Activation)     (None, 8, 8, 96)     0           batch_normalization_486[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_487 (Conv2D)             (None, 8, 8, 24)     2304        activation_486[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_483 (Dropout)           (None, 8, 8, 24)     0           conv2d_487[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_487 (BatchN (None, 8, 8, 24)     96          dropout_483[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_487 (Activation)     (None, 8, 8, 24)     0           batch_normalization_487[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_488 (Conv2D)             (None, 8, 8, 6)      1296        activation_487[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_484 (Dropout)           (None, 8, 8, 6)      0           conv2d_488[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_236 (Concatenate)   (None, 8, 8, 102)    0           concatenate_235[0][0]            \n",
            "                                                                 dropout_484[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_488 (BatchN (None, 8, 8, 102)    408         concatenate_236[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_488 (Activation)     (None, 8, 8, 102)    0           batch_normalization_488[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_489 (Conv2D)             (None, 8, 8, 24)     2448        activation_488[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_485 (Dropout)           (None, 8, 8, 24)     0           conv2d_489[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_489 (BatchN (None, 8, 8, 24)     96          dropout_485[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_489 (Activation)     (None, 8, 8, 24)     0           batch_normalization_489[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_490 (Conv2D)             (None, 8, 8, 6)      1296        activation_489[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_486 (Dropout)           (None, 8, 8, 6)      0           conv2d_490[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_237 (Concatenate)   (None, 8, 8, 108)    0           concatenate_236[0][0]            \n",
            "                                                                 dropout_486[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_490 (BatchN (None, 8, 8, 108)    432         concatenate_237[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_490 (Activation)     (None, 8, 8, 108)    0           batch_normalization_490[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_491 (Conv2D)             (None, 8, 8, 24)     2592        activation_490[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_487 (Dropout)           (None, 8, 8, 24)     0           conv2d_491[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_491 (BatchN (None, 8, 8, 24)     96          dropout_487[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_491 (Activation)     (None, 8, 8, 24)     0           batch_normalization_491[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_492 (Conv2D)             (None, 8, 8, 6)      1296        activation_491[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_488 (Dropout)           (None, 8, 8, 6)      0           conv2d_492[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_238 (Concatenate)   (None, 8, 8, 114)    0           concatenate_237[0][0]            \n",
            "                                                                 dropout_488[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_492 (BatchN (None, 8, 8, 114)    456         concatenate_238[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_492 (Activation)     (None, 8, 8, 114)    0           batch_normalization_492[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_493 (Conv2D)             (None, 8, 8, 24)     2736        activation_492[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_489 (Dropout)           (None, 8, 8, 24)     0           conv2d_493[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_493 (BatchN (None, 8, 8, 24)     96          dropout_489[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_493 (Activation)     (None, 8, 8, 24)     0           batch_normalization_493[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_494 (Conv2D)             (None, 8, 8, 6)      1296        activation_493[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_490 (Dropout)           (None, 8, 8, 6)      0           conv2d_494[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_239 (Concatenate)   (None, 8, 8, 120)    0           concatenate_238[0][0]            \n",
            "                                                                 dropout_490[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_494 (BatchN (None, 8, 8, 120)    480         concatenate_239[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_494 (Activation)     (None, 8, 8, 120)    0           batch_normalization_494[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_495 (Conv2D)             (None, 8, 8, 24)     2880        activation_494[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_491 (Dropout)           (None, 8, 8, 24)     0           conv2d_495[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 4, 4, 24)     0           dropout_491[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_495 (BatchN (None, 4, 4, 24)     96          average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_495 (Activation)     (None, 4, 4, 24)     0           batch_normalization_495[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_496 (Conv2D)             (None, 4, 4, 24)     576         activation_495[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_492 (Dropout)           (None, 4, 4, 24)     0           conv2d_496[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_496 (BatchN (None, 4, 4, 24)     96          dropout_492[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_496 (Activation)     (None, 4, 4, 24)     0           batch_normalization_496[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_497 (Conv2D)             (None, 4, 4, 6)      1296        activation_496[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_493 (Dropout)           (None, 4, 4, 6)      0           conv2d_497[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_240 (Concatenate)   (None, 4, 4, 30)     0           average_pooling2d_11[0][0]       \n",
            "                                                                 dropout_493[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_497 (BatchN (None, 4, 4, 30)     120         concatenate_240[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_497 (Activation)     (None, 4, 4, 30)     0           batch_normalization_497[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_498 (Conv2D)             (None, 4, 4, 24)     720         activation_497[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_494 (Dropout)           (None, 4, 4, 24)     0           conv2d_498[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_498 (BatchN (None, 4, 4, 24)     96          dropout_494[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_498 (Activation)     (None, 4, 4, 24)     0           batch_normalization_498[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_499 (Conv2D)             (None, 4, 4, 6)      1296        activation_498[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_495 (Dropout)           (None, 4, 4, 6)      0           conv2d_499[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_241 (Concatenate)   (None, 4, 4, 36)     0           concatenate_240[0][0]            \n",
            "                                                                 dropout_495[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_499 (BatchN (None, 4, 4, 36)     144         concatenate_241[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_499 (Activation)     (None, 4, 4, 36)     0           batch_normalization_499[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_500 (Conv2D)             (None, 4, 4, 24)     864         activation_499[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_496 (Dropout)           (None, 4, 4, 24)     0           conv2d_500[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_500 (BatchN (None, 4, 4, 24)     96          dropout_496[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_500 (Activation)     (None, 4, 4, 24)     0           batch_normalization_500[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_501 (Conv2D)             (None, 4, 4, 6)      1296        activation_500[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_497 (Dropout)           (None, 4, 4, 6)      0           conv2d_501[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_242 (Concatenate)   (None, 4, 4, 42)     0           concatenate_241[0][0]            \n",
            "                                                                 dropout_497[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_501 (BatchN (None, 4, 4, 42)     168         concatenate_242[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_501 (Activation)     (None, 4, 4, 42)     0           batch_normalization_501[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_502 (Conv2D)             (None, 4, 4, 24)     1008        activation_501[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_498 (Dropout)           (None, 4, 4, 24)     0           conv2d_502[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_502 (BatchN (None, 4, 4, 24)     96          dropout_498[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_502 (Activation)     (None, 4, 4, 24)     0           batch_normalization_502[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_503 (Conv2D)             (None, 4, 4, 6)      1296        activation_502[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_499 (Dropout)           (None, 4, 4, 6)      0           conv2d_503[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_243 (Concatenate)   (None, 4, 4, 48)     0           concatenate_242[0][0]            \n",
            "                                                                 dropout_499[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_503 (BatchN (None, 4, 4, 48)     192         concatenate_243[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_503 (Activation)     (None, 4, 4, 48)     0           batch_normalization_503[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_504 (Conv2D)             (None, 4, 4, 24)     1152        activation_503[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_500 (Dropout)           (None, 4, 4, 24)     0           conv2d_504[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_504 (BatchN (None, 4, 4, 24)     96          dropout_500[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_504 (Activation)     (None, 4, 4, 24)     0           batch_normalization_504[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_505 (Conv2D)             (None, 4, 4, 6)      1296        activation_504[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_501 (Dropout)           (None, 4, 4, 6)      0           conv2d_505[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_244 (Concatenate)   (None, 4, 4, 54)     0           concatenate_243[0][0]            \n",
            "                                                                 dropout_501[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_505 (BatchN (None, 4, 4, 54)     216         concatenate_244[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_505 (Activation)     (None, 4, 4, 54)     0           batch_normalization_505[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_506 (Conv2D)             (None, 4, 4, 24)     1296        activation_505[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_502 (Dropout)           (None, 4, 4, 24)     0           conv2d_506[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_506 (BatchN (None, 4, 4, 24)     96          dropout_502[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_506 (Activation)     (None, 4, 4, 24)     0           batch_normalization_506[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_507 (Conv2D)             (None, 4, 4, 6)      1296        activation_506[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_503 (Dropout)           (None, 4, 4, 6)      0           conv2d_507[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_245 (Concatenate)   (None, 4, 4, 60)     0           concatenate_244[0][0]            \n",
            "                                                                 dropout_503[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_507 (BatchN (None, 4, 4, 60)     240         concatenate_245[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_507 (Activation)     (None, 4, 4, 60)     0           batch_normalization_507[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_508 (Conv2D)             (None, 4, 4, 24)     1440        activation_507[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_504 (Dropout)           (None, 4, 4, 24)     0           conv2d_508[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_508 (BatchN (None, 4, 4, 24)     96          dropout_504[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_508 (Activation)     (None, 4, 4, 24)     0           batch_normalization_508[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_509 (Conv2D)             (None, 4, 4, 6)      1296        activation_508[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_505 (Dropout)           (None, 4, 4, 6)      0           conv2d_509[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_246 (Concatenate)   (None, 4, 4, 66)     0           concatenate_245[0][0]            \n",
            "                                                                 dropout_505[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_509 (BatchN (None, 4, 4, 66)     264         concatenate_246[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_509 (Activation)     (None, 4, 4, 66)     0           batch_normalization_509[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_510 (Conv2D)             (None, 4, 4, 24)     1584        activation_509[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_506 (Dropout)           (None, 4, 4, 24)     0           conv2d_510[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_510 (BatchN (None, 4, 4, 24)     96          dropout_506[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_510 (Activation)     (None, 4, 4, 24)     0           batch_normalization_510[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_511 (Conv2D)             (None, 4, 4, 6)      1296        activation_510[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_507 (Dropout)           (None, 4, 4, 6)      0           conv2d_511[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_247 (Concatenate)   (None, 4, 4, 72)     0           concatenate_246[0][0]            \n",
            "                                                                 dropout_507[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_511 (BatchN (None, 4, 4, 72)     288         concatenate_247[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_511 (Activation)     (None, 4, 4, 72)     0           batch_normalization_511[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_512 (Conv2D)             (None, 4, 4, 24)     1728        activation_511[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_508 (Dropout)           (None, 4, 4, 24)     0           conv2d_512[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_512 (BatchN (None, 4, 4, 24)     96          dropout_508[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_512 (Activation)     (None, 4, 4, 24)     0           batch_normalization_512[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_513 (Conv2D)             (None, 4, 4, 6)      1296        activation_512[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_509 (Dropout)           (None, 4, 4, 6)      0           conv2d_513[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_248 (Concatenate)   (None, 4, 4, 78)     0           concatenate_247[0][0]            \n",
            "                                                                 dropout_509[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_513 (BatchN (None, 4, 4, 78)     312         concatenate_248[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_513 (Activation)     (None, 4, 4, 78)     0           batch_normalization_513[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_514 (Conv2D)             (None, 4, 4, 24)     1872        activation_513[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_510 (Dropout)           (None, 4, 4, 24)     0           conv2d_514[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_514 (BatchN (None, 4, 4, 24)     96          dropout_510[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_514 (Activation)     (None, 4, 4, 24)     0           batch_normalization_514[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_515 (Conv2D)             (None, 4, 4, 6)      1296        activation_514[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_511 (Dropout)           (None, 4, 4, 6)      0           conv2d_515[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_249 (Concatenate)   (None, 4, 4, 84)     0           concatenate_248[0][0]            \n",
            "                                                                 dropout_511[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_515 (BatchN (None, 4, 4, 84)     336         concatenate_249[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_515 (Activation)     (None, 4, 4, 84)     0           batch_normalization_515[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_516 (Conv2D)             (None, 4, 4, 24)     2016        activation_515[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_512 (Dropout)           (None, 4, 4, 24)     0           conv2d_516[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_516 (BatchN (None, 4, 4, 24)     96          dropout_512[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_516 (Activation)     (None, 4, 4, 24)     0           batch_normalization_516[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_517 (Conv2D)             (None, 4, 4, 6)      1296        activation_516[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_513 (Dropout)           (None, 4, 4, 6)      0           conv2d_517[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_250 (Concatenate)   (None, 4, 4, 90)     0           concatenate_249[0][0]            \n",
            "                                                                 dropout_513[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_517 (BatchN (None, 4, 4, 90)     360         concatenate_250[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_517 (Activation)     (None, 4, 4, 90)     0           batch_normalization_517[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_518 (Conv2D)             (None, 4, 4, 24)     2160        activation_517[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_514 (Dropout)           (None, 4, 4, 24)     0           conv2d_518[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_518 (BatchN (None, 4, 4, 24)     96          dropout_514[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_518 (Activation)     (None, 4, 4, 24)     0           batch_normalization_518[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_519 (Conv2D)             (None, 4, 4, 6)      1296        activation_518[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_515 (Dropout)           (None, 4, 4, 6)      0           conv2d_519[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_251 (Concatenate)   (None, 4, 4, 96)     0           concatenate_250[0][0]            \n",
            "                                                                 dropout_515[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_519 (BatchN (None, 4, 4, 96)     384         concatenate_251[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_519 (Activation)     (None, 4, 4, 96)     0           batch_normalization_519[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_520 (Conv2D)             (None, 4, 4, 24)     2304        activation_519[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_516 (Dropout)           (None, 4, 4, 24)     0           conv2d_520[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_520 (BatchN (None, 4, 4, 24)     96          dropout_516[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_520 (Activation)     (None, 4, 4, 24)     0           batch_normalization_520[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_521 (Conv2D)             (None, 4, 4, 6)      1296        activation_520[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_517 (Dropout)           (None, 4, 4, 6)      0           conv2d_521[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_252 (Concatenate)   (None, 4, 4, 102)    0           concatenate_251[0][0]            \n",
            "                                                                 dropout_517[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_521 (BatchN (None, 4, 4, 102)    408         concatenate_252[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_521 (Activation)     (None, 4, 4, 102)    0           batch_normalization_521[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_522 (Conv2D)             (None, 4, 4, 24)     2448        activation_521[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_518 (Dropout)           (None, 4, 4, 24)     0           conv2d_522[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_522 (BatchN (None, 4, 4, 24)     96          dropout_518[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_522 (Activation)     (None, 4, 4, 24)     0           batch_normalization_522[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_523 (Conv2D)             (None, 4, 4, 6)      1296        activation_522[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_519 (Dropout)           (None, 4, 4, 6)      0           conv2d_523[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_253 (Concatenate)   (None, 4, 4, 108)    0           concatenate_252[0][0]            \n",
            "                                                                 dropout_519[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_523 (BatchN (None, 4, 4, 108)    432         concatenate_253[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_523 (Activation)     (None, 4, 4, 108)    0           batch_normalization_523[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_524 (Conv2D)             (None, 4, 4, 24)     2592        activation_523[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_520 (Dropout)           (None, 4, 4, 24)     0           conv2d_524[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_524 (BatchN (None, 4, 4, 24)     96          dropout_520[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_524 (Activation)     (None, 4, 4, 24)     0           batch_normalization_524[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_525 (Conv2D)             (None, 4, 4, 6)      1296        activation_524[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_521 (Dropout)           (None, 4, 4, 6)      0           conv2d_525[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_254 (Concatenate)   (None, 4, 4, 114)    0           concatenate_253[0][0]            \n",
            "                                                                 dropout_521[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_525 (BatchN (None, 4, 4, 114)    456         concatenate_254[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_525 (Activation)     (None, 4, 4, 114)    0           batch_normalization_525[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_526 (Conv2D)             (None, 4, 4, 24)     2736        activation_525[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_522 (Dropout)           (None, 4, 4, 24)     0           conv2d_526[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_526 (BatchN (None, 4, 4, 24)     96          dropout_522[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_526 (Activation)     (None, 4, 4, 24)     0           batch_normalization_526[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_527 (Conv2D)             (None, 4, 4, 6)      1296        activation_526[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_523 (Dropout)           (None, 4, 4, 6)      0           conv2d_527[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_255 (Concatenate)   (None, 4, 4, 120)    0           concatenate_254[0][0]            \n",
            "                                                                 dropout_523[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_527 (BatchN (None, 4, 4, 120)    480         concatenate_255[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_527 (Activation)     (None, 4, 4, 120)    0           batch_normalization_527[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 120)          0           activation_527[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           1210        global_average_pooling2d_3[0][0] \n",
            "==================================================================================================\n",
            "Total params: 219,118\n",
            "Trainable params: 206,662\n",
            "Non-trainable params: 12,456\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep-T_WB7yRo_"
      },
      "source": [
        "#callbacks\n",
        "from time import time\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "\n",
        "filepath = \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
        "history = tf.keras.callbacks.History()\n",
        "\n",
        "# tensorboard\n",
        "tensorboard = TensorBoard(log_dir=\"model_logs/{}\".format(time()))\n",
        "\n",
        "filepath = \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
        "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.0001)\n",
        "checkpoint_save = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "callbacks_list = [checkpoint_save,learning_rate_reduction,history,tensorboard]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD5N6JuppMV3"
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 64\n",
        "steps = len(x_train)//batch_size"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c11ti0aFpmLL"
      },
      "source": [
        "sgd = tf.keras.optimizers.SGD(lr = 0.1,momentum = 0.9,nesterov = True)\n",
        "model.compile(sgd,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEB4A9TR2_lB"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=0.3,\n",
        "    rotation_range=15,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XILHmv-5ypdQ",
        "outputId": "0b10f1ef-4d78-4cbf-e140-27baab5d230c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=64),steps_per_epoch=steps,\n",
        "                    epochs=100,callbacks=callbacks_list,\n",
        "                    validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/781 [..............................] - ETA: 7:52 - loss: 2.4242 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1043s vs `on_train_batch_end` time: 1.1073s). Check your callbacks.\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.7641 - accuracy: 0.3467WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 98s 125ms/step - loss: 1.7641 - accuracy: 0.3467 - val_loss: 1.7769 - val_accuracy: 0.3758\n",
            "Epoch 2/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.4675 - accuracy: 0.4629WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 1.4675 - accuracy: 0.4629 - val_loss: 1.7534 - val_accuracy: 0.3736\n",
            "Epoch 3/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.3102 - accuracy: 0.5282WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 1.3102 - accuracy: 0.5282 - val_loss: 1.4225 - val_accuracy: 0.5202\n",
            "Epoch 4/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.1959 - accuracy: 0.5705WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 1.1959 - accuracy: 0.5705 - val_loss: 1.9301 - val_accuracy: 0.4961\n",
            "Epoch 5/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.1094 - accuracy: 0.6030WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 1.1094 - accuracy: 0.6030 - val_loss: 1.4003 - val_accuracy: 0.5737\n",
            "Epoch 6/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.0490 - accuracy: 0.6274WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 1.0490 - accuracy: 0.6274 - val_loss: 1.2444 - val_accuracy: 0.6234\n",
            "Epoch 7/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.0042 - accuracy: 0.6447WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 120ms/step - loss: 1.0042 - accuracy: 0.6447 - val_loss: 1.1140 - val_accuracy: 0.6371\n",
            "Epoch 8/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.9588 - accuracy: 0.6615WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.9588 - accuracy: 0.6615 - val_loss: 1.0060 - val_accuracy: 0.6789\n",
            "Epoch 9/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.9251 - accuracy: 0.6728WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.9251 - accuracy: 0.6728 - val_loss: 0.9360 - val_accuracy: 0.6881\n",
            "Epoch 10/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.8931 - accuracy: 0.6832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.8931 - accuracy: 0.6832 - val_loss: 1.6559 - val_accuracy: 0.5714\n",
            "Epoch 11/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.8665 - accuracy: 0.6937WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.8665 - accuracy: 0.6937 - val_loss: 0.9947 - val_accuracy: 0.7049\n",
            "Epoch 12/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.8362 - accuracy: 0.7041WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.8362 - accuracy: 0.7041 - val_loss: 1.2381 - val_accuracy: 0.6532\n",
            "Epoch 13/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.8257 - accuracy: 0.7090WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.8257 - accuracy: 0.7090 - val_loss: 0.9974 - val_accuracy: 0.6990\n",
            "Epoch 14/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.8046 - accuracy: 0.7173WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.8046 - accuracy: 0.7173 - val_loss: 1.0191 - val_accuracy: 0.6998\n",
            "Epoch 15/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7818 - accuracy: 0.7253WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.7818 - accuracy: 0.7253 - val_loss: 1.2902 - val_accuracy: 0.6558\n",
            "Epoch 16/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7645 - accuracy: 0.7331WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.7645 - accuracy: 0.7331 - val_loss: 1.2700 - val_accuracy: 0.6632\n",
            "Epoch 17/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7565 - accuracy: 0.7339WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.7565 - accuracy: 0.7339 - val_loss: 0.7638 - val_accuracy: 0.7631\n",
            "Epoch 18/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7401 - accuracy: 0.7402WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.7401 - accuracy: 0.7402 - val_loss: 1.0865 - val_accuracy: 0.7062\n",
            "Epoch 19/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7285 - accuracy: 0.7448WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.7285 - accuracy: 0.7448 - val_loss: 0.9484 - val_accuracy: 0.7188\n",
            "Epoch 20/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7165 - accuracy: 0.7486WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.7165 - accuracy: 0.7486 - val_loss: 0.7255 - val_accuracy: 0.7742\n",
            "Epoch 21/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7060 - accuracy: 0.7522WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.7060 - accuracy: 0.7522 - val_loss: 0.7166 - val_accuracy: 0.7822\n",
            "Epoch 22/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.7570WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.6956 - accuracy: 0.7570 - val_loss: 0.6863 - val_accuracy: 0.7848\n",
            "Epoch 23/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6881 - accuracy: 0.7607WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.6881 - accuracy: 0.7607 - val_loss: 0.6766 - val_accuracy: 0.7934\n",
            "Epoch 24/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6779 - accuracy: 0.7637WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.6779 - accuracy: 0.7637 - val_loss: 0.7797 - val_accuracy: 0.7663\n",
            "Epoch 25/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6694 - accuracy: 0.7663WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.6694 - accuracy: 0.7663 - val_loss: 0.7502 - val_accuracy: 0.7770\n",
            "Epoch 26/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6660 - accuracy: 0.7683WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 93s 119ms/step - loss: 0.6660 - accuracy: 0.7683 - val_loss: 0.8621 - val_accuracy: 0.7519\n",
            "Epoch 27/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6545 - accuracy: 0.7707WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 93s 119ms/step - loss: 0.6545 - accuracy: 0.7707 - val_loss: 0.7887 - val_accuracy: 0.7679\n",
            "Epoch 28/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6558 - accuracy: 0.7722WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 93s 119ms/step - loss: 0.6558 - accuracy: 0.7722 - val_loss: 0.7536 - val_accuracy: 0.7759\n",
            "Epoch 29/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.7759WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 93s 120ms/step - loss: 0.6445 - accuracy: 0.7759 - val_loss: 0.6899 - val_accuracy: 0.7953\n",
            "Epoch 30/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.7775WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.6362 - accuracy: 0.7775 - val_loss: 0.7485 - val_accuracy: 0.7807\n",
            "Epoch 31/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6341 - accuracy: 0.7791WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.6341 - accuracy: 0.7791 - val_loss: 0.9044 - val_accuracy: 0.7451\n",
            "Epoch 32/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6241 - accuracy: 0.7803WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 120ms/step - loss: 0.6241 - accuracy: 0.7803 - val_loss: 0.7007 - val_accuracy: 0.7982\n",
            "Epoch 33/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.7845WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.6225 - accuracy: 0.7845 - val_loss: 0.8759 - val_accuracy: 0.7568\n",
            "Epoch 34/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.7830WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.6168 - accuracy: 0.7830 - val_loss: 0.6616 - val_accuracy: 0.7965\n",
            "Epoch 35/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6108 - accuracy: 0.7860WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 120ms/step - loss: 0.6108 - accuracy: 0.7860 - val_loss: 0.6749 - val_accuracy: 0.8040\n",
            "Epoch 36/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6044 - accuracy: 0.7903WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 120ms/step - loss: 0.6044 - accuracy: 0.7903 - val_loss: 0.5177 - val_accuracy: 0.8389\n",
            "Epoch 37/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6017 - accuracy: 0.7911WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 120ms/step - loss: 0.6017 - accuracy: 0.7911 - val_loss: 0.5864 - val_accuracy: 0.8200\n",
            "Epoch 38/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5942 - accuracy: 0.7928WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 120ms/step - loss: 0.5942 - accuracy: 0.7928 - val_loss: 0.6205 - val_accuracy: 0.8152\n",
            "Epoch 39/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5932 - accuracy: 0.7927WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.5932 - accuracy: 0.7927 - val_loss: 0.5567 - val_accuracy: 0.8244\n",
            "Epoch 40/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.7956WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.5856 - accuracy: 0.7956 - val_loss: 0.8312 - val_accuracy: 0.7801\n",
            "Epoch 41/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5840 - accuracy: 0.7973WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.5840 - accuracy: 0.7973 - val_loss: 0.6728 - val_accuracy: 0.8044\n",
            "Epoch 42/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.7997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.5742 - accuracy: 0.7997 - val_loss: 0.6814 - val_accuracy: 0.8058\n",
            "Epoch 43/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.7979WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 120ms/step - loss: 0.5749 - accuracy: 0.7979 - val_loss: 0.6851 - val_accuracy: 0.7980\n",
            "Epoch 44/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.8018WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 120ms/step - loss: 0.5685 - accuracy: 0.8018 - val_loss: 0.5475 - val_accuracy: 0.8326\n",
            "Epoch 45/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.8036WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.5671 - accuracy: 0.8036 - val_loss: 0.6850 - val_accuracy: 0.7989\n",
            "Epoch 46/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.8046WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 120ms/step - loss: 0.5620 - accuracy: 0.8046 - val_loss: 0.6171 - val_accuracy: 0.8232\n",
            "Epoch 47/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.8022WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.5626 - accuracy: 0.8022 - val_loss: 0.5991 - val_accuracy: 0.8253\n",
            "Epoch 48/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5562 - accuracy: 0.8061WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.5562 - accuracy: 0.8061 - val_loss: 0.7218 - val_accuracy: 0.7922\n",
            "Epoch 49/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.5507 - accuracy: 0.8078WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "781/781 [==============================] - 97s 124ms/step - loss: 0.5507 - accuracy: 0.8078 - val_loss: 0.7972 - val_accuracy: 0.7891\n",
            "Epoch 50/100\n",
            "751/781 [===========================>..] - ETA: 3s - loss: 0.5544 - accuracy: 0.8060"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}